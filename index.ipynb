{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you made it to your first lab! In this lab, you'll practice everything you have learned during the lecture. We know there is quite a bit of math involved, but don't worry! Using Python and trying things out yourself will actually make a lot of things much more clear! Before we start, let's load some necessary libraries so we can import our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "* Import images using Keras\n",
    "* Build a simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we'll start by importing the necessary packages that we'll use in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/conda/envs/learn-env/lib/python3.6/site-packages (6.0.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll get a bunch of images, and the purpose is to correctly classify these images as \"Santa\", meaning that Santa is present on the image or \"not Santa\" meaning that something else is in the images. \n",
    "\n",
    "If you have a look at this github repository, you'll notice that the images are simply stored in .jpeg-files and stored under the folder `/data`. Luckily, `keras` had great modules that make importing images stored in this type of format easy. We'll do this for you in the code below.\n",
    "\n",
    "The images in the `/data` folder have various resultions. We will reshape them so they are all have 64 x 64 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000386.jpg  00000401.jpg  00000416.jpg  00000431.jpg\t00000446.jpg\r\n",
      "00000387.jpg  00000402.jpg  00000417.jpg  00000432.jpg\t00000447.jpg\r\n",
      "00000388.jpg  00000403.jpg  00000418.jpg  00000433.jpg\t00000448.jpg\r\n",
      "00000389.jpg  00000404.jpg  00000419.jpg  00000434.jpg\t00000449.jpg\r\n",
      "00000390.jpg  00000405.jpg  00000420.jpg  00000435.jpg\t00000450.jpg\r\n",
      "00000391.jpg  00000406.jpg  00000421.jpg  00000436.jpg\t00000451.jpg\r\n",
      "00000392.jpg  00000407.jpg  00000422.jpg  00000437.jpg\t00000452.jpg\r\n",
      "00000393.jpg  00000408.jpg  00000423.jpg  00000438.jpg\t00000453.jpg\r\n",
      "00000394.jpg  00000409.jpg  00000424.jpg  00000439.jpg\t00000454.jpg\r\n",
      "00000395.jpg  00000410.jpg  00000425.jpg  00000440.jpg\t00000455.jpg\r\n",
      "00000396.jpg  00000411.jpg  00000426.jpg  00000441.jpg\t00000456.jpg\r\n",
      "00000397.jpg  00000412.jpg  00000427.jpg  00000442.jpg\t00000457.jpg\r\n",
      "00000398.jpg  00000413.jpg  00000428.jpg  00000443.jpg\t00000458.jpg\r\n",
      "00000399.jpg  00000414.jpg  00000429.jpg  00000444.jpg\t00000459.jpg\r\n",
      "00000400.jpg  00000415.jpg  00000430.jpg  00000445.jpg\t00000460.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/validation/not_santa/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 132 images belonging to 2 classes.\n",
      "Found 790 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# directory path\n",
    "train_data_dir = 'data/train'\n",
    "test_data_dir = 'data/validation'\n",
    "\n",
    "# get all the data in the directory data/validation (132 images), and reshape them\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, \n",
    "        target_size=(64, 64), batch_size=132)\n",
    "\n",
    "# get all the data in the directory data/train (790 images), and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, \n",
    "        target_size=(64, 64), batch_size=790)\n",
    "\n",
    "# create the data sets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting and preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at some images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have 4 numpy arrays now: `train_images`, `train_labels`, `test_images`, `test_labels`. We'll need to make some changes to the data in order to make them workable, but before we do anything else, let's have a look at some of the images we loaded. We'll look at some images in train_images. You can use `array_to_img()` from `keras.processing.image` on any `train_image` (select any train_image by doing `train_image[index]` to look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F1070768518>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here preview an image \n",
    "array_to_img(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F105F339B70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here preview a second image\n",
    "array_to_img(test_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The shape of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use `np.shape()` to look at what these numpy arrays look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the shape of both the images and labels for both the train and test set (4 objects total)\n",
    "# Your code here\n",
    "test_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 64, 64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  `train_images` and `test_images`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with `train_images`. From the lecture, you might remember that the expected input shape is $n$ x $l$. How does this relate to what we see here?\n",
    "\n",
    "$l$ denotes the number of observations, or the number of images. The number of images in `train_images` is 790. $n$ is the number of elements in the feature vector for each image, or put differently, $n$ is the number of rows when unrowing the 3 (RGB) 64 x 64 matrices. \n",
    "\n",
    "So, translated to this example, we need to transform our `(790, 64, 64, 3)` matrix to a `(64*64*3, 790)` matrix! Hint: you should use both the `.reshape`-function and a transpose `.T`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288, 790)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_img_unrow = #Reshape the train images using the hints above\n",
    "train_images.shape\n",
    "train_img_unrow = train_images.reshape(790, 64*64*3).T\n",
    "train_img_unrow = train_images.reshape(790, -1).T\n",
    "train_img_unrow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use np.shape on the newly created `train_img_unrow` to verify that the shape is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288, 790)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here; Preview the shape of your new object\n",
    "train_img_unrow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's transform test_images in a similar way. Note that the dimensions are different here! Where we needed to have a matrix shape if $ n$ x $l $ for `train_images`, for `test_images`, we need to get to a shape of $ n$ x $m$. What is $m$ here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = #Define appropriate m \n",
    "m = test_images.shape[0]\n",
    "test_img_unrow = test_images.reshape(m, -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12288, 132)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here; Once again preview the shape of your updated object\n",
    "test_img_unrow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `train_labels` and `test_labels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier, you noticed that `train_labels` and `test_labels` have shapes of $(790, 2)$ and $(132, 2)$ respectively. In the lecture, we expected $1$ x $l$ and $1$ x $m$.\n",
    "\n",
    "Let's have a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels #Run this block of code; no need to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(790, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this, it's clear that for each observation (or image), train_labels doesn't simply have an output of 1 or 0, but a pair either `[0,1]` or `[1,0]`.\n",
    "\n",
    "Having this information, we still don't know which pair correcponds with `santa` versus `not_santa`. Luckily, what this was stored using `keras.preprocessing_image`, and you can get more info using the command `train_generator.class_indices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not_santa': 0, 'santa': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices #Run this block of code; no need to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index 0 (the first column) represents `not_santa`, index 1 represents `santa`. Select one of the two columns and transpose the result such that you get a $1$ x $l$ and $1$ x $m$ vector respectively, and value `1` represents `santa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels_final = #Your code here\n",
    "train_labels_final = train_labels[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(790,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_labels_final) #Run this block of code; no need to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels_final = #Your code here; same as above but for the test labels.\n",
    "test_labels_final = test_labels[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_labels_final) #Run this block of code; no need to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final sanity check, look at an image and the corresponding label, so we're sure that santa is indeed stored as `1`.\n",
    "\n",
    "- First, use `array_to_image` again on the original `train_images` with index 240 to look at this particular image.\n",
    "- Use train_labels_final to get the 240th label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F105F30BE10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here; preview train images 240\n",
    "array_to_img(train_images[240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here; preview train labels 240\n",
    "train_labels_final[240]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be correct! Feel free to try out other indices as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lastly, you'll want to standardize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that each RGB pixel in an image takes a value between 0 and 255. In Deep Learning, it is very common to standardize and/or center your data set. For images, a common thing that is done is to make sure each pixel value is between 0 and 1. This can be done by dividing the entire matrix by 255. Do this here for the `train_img_unrow` and `test_img_unrow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "train_img_unrow /= 255\n",
    "test_img_unrow /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, we'll work with `train_img_final`, `test_img_final`, `train_labels_final`, `test_labels_final`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a logistic regression-based neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go ahead and build our own basic logistic regression-based neural network to disctinguish images with Santa from images without Santa. You've seen in the lecture that logistic regression can actually be represented a a very simple neural network.\n",
    "\n",
    "Remember that we defined that, for each $x^{(i)}$:\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat y ^{(i)}, y^{(i)}) =  - \\big( y^{(i)} \\log(\\hat y^{(i)}) + (1-y^{(i)} )  \\log(1-\\hat y^{(i)})\\big)$$\n",
    "\n",
    "$$\\hat{y}^{(i)} = \\sigma(z^{(i)}) = \\frac{1}{1 + e^{-(z^{(i)})}}$$ \n",
    "\n",
    "$$z^{(i)} = w^T x^{(i)} + b$$\n",
    "\n",
    "The cost function is then given by:\n",
    "$$J(w,b) = \\dfrac{1}{l}\\displaystyle\\sum^l_{i=1}\\mathcal{L}(\\hat y^{(i)}, y^{(i)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the remainder of this lab, you'll do the following:\n",
    "\n",
    "   - You'll learn how to initialize the parameters of the model\n",
    "   - You'll perform forward propagation, and calculate the current loss\n",
    "   - You'll perform backward propagation (which is basically calculating the current gradient)\n",
    "   - You'll update the parameters (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w$ and $b$ are the unknown parameters to start with. We'll initialize them as 0.\n",
    "- remember that $b$ is a scalar\n",
    "- $w$ however, is a vector of shape $n$ x $1$, with $n$ being `horiz_pixel x vertic_pixel x 3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Initialize b as a scalar with value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "b = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function `init_w(n)` such that when n is filled out, you get a vector with zeros that has a shape $n$ x $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; define your function\n",
    "def init_w(n):\n",
    "    return np.zeros((n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_w(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.],\n",
       "        [0.],\n",
       "        [0.]]), (12288, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here; call your function using appropriate parameters\n",
    "n = 64*64*3\n",
    "w = init_w(n)\n",
    "w[:3], w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward Propagation:\n",
    "- You get `x`\n",
    "- You compute `y_hat`: \n",
    "$$ (\\hat y^{(1)}, \\hat y^{(2)}, \\ldots , \\hat y^{(l)})= \\sigma(w^T x + b) = \\Biggr(\\dfrac{1}{1+exp-(w^T x^{(1)}+ b)},\\ldots, \\dfrac{1}{1+exp-(w^T x^{(l)}+ b)}\\Biggr) $$\n",
    "- You calculate the `cost` function: $J(w,b) = -\\dfrac{1}{l}\\displaystyle\\sum_{i=1}^{l}y^{(i)}\\log(\\hat y^{(i)})+(1-y^{(i)})\\log(1-\\hat y^{(i)})$\n",
    "\n",
    "Here are the two formulas you will be using to compute the gradients. Don't be scared off by the mathematics. The long formulas are just to show that this corresponds with what we derived in the lectures!\n",
    "\n",
    "$$ \\frac{dJ(w,b)}{dw} = \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} \\frac{d\\mathcal{L}(\\hat y^{(i)}, y^{(i)})}{dw}= \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} x^{(i)} dz^{(i)}  = \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} x^{(i)}(\\hat y^{(i)}-y^{(i)})  = \\frac{1}{l}x(\\hat y-y)^T$$\n",
    "\n",
    "$$ \\frac{dJ(w,b)}{db} = \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} \\frac{d\\mathcal{L}(\\hat y^{(i)}, y^{(i)})}{db}= \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} dz^{(i)}  = \\displaystyle\\frac{1}{l}\\displaystyle\\sum^l_{i=1} (\\hat y^{(i)}-y^{(i)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; define the propagation function\n",
    "def propagate(w, b, x, y):\n",
    "    l = x.shape[0]\n",
    "    z = w.T @ x + b\n",
    "    y_hat = 1 / (1 + np.exp(-z))\n",
    "    cost = (-1 / l) * (y * (np.log(y_hat)) + (1-y) * np.log(1-y_hat)).sum()\n",
    "    dw = (1 / l) * (x @ (y_hat - y).T)\n",
    "    db = (1 / l) * (y_hat - y).sum()\n",
    "    return dw, db, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dw, db, cost = #Your code here; use your propogation function to return d2, db and the associated cost\n",
    "dw, db, cost = propagate(w=w, b=b, x=train_img_unrow, y=train_labels_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0037186 ]\n",
      " [-0.00349504]\n",
      " [-0.00409342]\n",
      " ...\n",
      " [-0.00481085]\n",
      " [-0.00430246]\n",
      " [-0.00466915]]\n",
      "-0.000732421875\n",
      "0.04456268494810845\n"
     ]
    }
   ],
   "source": [
    "print(dw)\n",
    "\n",
    "print(db)\n",
    "\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in the optimization step, we have to update $w$ and $b$ as follows:\n",
    "\n",
    "$$w := w - \\alpha * dw$$\n",
    "$$b := b - \\alpha * db$$\n",
    "\n",
    "Note that this `optimization` function also takes in the propagation function. It loops over the `propagation` function in each iteration, and updates both $w$ and $b$ right after that! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the function below using your propogation function to define dw, db and cost. \n",
    "#Then use the formula above to update w and b in the optimization function.\n",
    "def optimization(w, b, x, y, num_iterations, learning_rate, print_cost = False):\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        dw, db, cost = propagate(b=b, w=w, x=x, y=y,) #Your code here \n",
    "        w = w - learning_rate * dw #Your code here\n",
    "        b = b - learning_rate * db #Your code here\n",
    "        \n",
    "        # Record the costs and print them every 50 iterations\n",
    "        if i % 50 == 0:\n",
    "            costs.append(cost)\n",
    "        if print_cost and i % 50 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    return w, b, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.044563\n",
      "Cost after iteration 50: 0.044234\n",
      "Cost after iteration 100: 0.044030\n",
      "Cost after iteration 150: 0.043899\n"
     ]
    }
   ],
   "source": [
    "#Run this block of code as is\n",
    "w, b, costs = optimization(w, b, train_img_unrow,\n",
    "                           train_labels_final, num_iterations= 151,\n",
    "                           learning_rate = 0.0001, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make label predictions: Santa or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a function that makes label predictions. We'll later use this when we will look at our Santa pictures. What we want, is a label that is equal to 1 when the predicted $y$ is bigger than 0.5, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(w, b, x):\n",
    "    l = x.shape[1]\n",
    "    y_prediction = np.zeros((1,l)) #Initialize a prediction vector\n",
    "#     w = w.reshape(x.shape[0], 1)\n",
    "    z = w.T @ x + b #Your code here; the sigmoid function given w, b and x\n",
    "    y_hat = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "#     print(y_hat)\n",
    "    \n",
    "#     print(y_prediction)\n",
    "    \n",
    "    for i in range(y_hat.shape[1]):\n",
    "        #Transform the probability into a binary classification using 0.5 as the cutoff\n",
    "        if y_hat[0][i] > 0.5:\n",
    "            y_prediction[0,i] = 1\n",
    "        else:\n",
    "            y_prediction[0,i] = 0\n",
    "    return y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this out on a small example. Make sure to have 4 predictions in your output here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59228028 0.51369657 0.47749023 0.39484293]]\n",
      "[[0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this block of code as is\n",
    "w = np.array([[0.035],[0.123],[0.217]])\n",
    "b = 0.2\n",
    "x = np.array([[0.2,0.4,-1.2,-2],[1,-2.,0.1,-1],[0.2,0.4,-1.2,-2]])\n",
    "\n",
    "prediction(w,b,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The overall model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build the overall model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is provided to you as is, but should be carefully reviewed.\n",
    "def model(x_train, y_train, x_test, y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "\n",
    "    b = 0\n",
    "    w = init_w(np.shape(x_train)[0]) \n",
    "\n",
    "    # Gradient descent (≈ 1 line of code)\n",
    "    w, b, costs = optimization(w, b, x_train, y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    y_pred_test = prediction(w, b, x_test)\n",
    "    y_pred_train = prediction(w, b, x_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_test - y_test)) * 100))\n",
    "\n",
    "    output = {\"costs\": costs,\n",
    "         \"y_pred_test\": y_pred_test, \n",
    "         \"y_pred_train\" : y_pred_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.044563\n",
      "Cost after iteration 50: 0.042482\n",
      "Cost after iteration 100: 0.041302\n",
      "Cost after iteration 150: 0.040264\n",
      "Cost after iteration 200: 0.039342\n",
      "Cost after iteration 250: 0.038517\n",
      "Cost after iteration 300: 0.037771\n",
      "Cost after iteration 350: 0.037092\n",
      "Cost after iteration 400: 0.036470\n",
      "Cost after iteration 450: 0.035897\n",
      "Cost after iteration 500: 0.035366\n",
      "Cost after iteration 550: 0.034872\n",
      "Cost after iteration 600: 0.034411\n",
      "Cost after iteration 650: 0.033978\n",
      "Cost after iteration 700: 0.033570\n",
      "Cost after iteration 750: 0.033185\n",
      "Cost after iteration 800: 0.032820\n",
      "Cost after iteration 850: 0.032473\n",
      "Cost after iteration 900: 0.032144\n",
      "Cost after iteration 950: 0.031829\n",
      "Cost after iteration 1000: 0.031529\n",
      "Cost after iteration 1050: 0.031241\n",
      "Cost after iteration 1100: 0.030965\n",
      "Cost after iteration 1150: 0.030700\n",
      "Cost after iteration 1200: 0.030445\n",
      "Cost after iteration 1250: 0.030199\n",
      "Cost after iteration 1300: 0.029963\n",
      "Cost after iteration 1350: 0.029734\n",
      "Cost after iteration 1400: 0.029513\n",
      "Cost after iteration 1450: 0.029299\n",
      "Cost after iteration 1500: 0.029092\n",
      "Cost after iteration 1550: 0.028892\n",
      "Cost after iteration 1600: 0.028697\n",
      "Cost after iteration 1650: 0.028508\n",
      "Cost after iteration 1700: 0.028325\n",
      "Cost after iteration 1750: 0.028146\n",
      "Cost after iteration 1800: 0.027973\n",
      "Cost after iteration 1850: 0.027804\n",
      "Cost after iteration 1900: 0.027639\n",
      "Cost after iteration 1950: 0.027479\n",
      "[[0.28010912 0.85195912 0.79369986 0.26083151 0.09416533 0.80426434\n",
      "  0.7317291  0.30002315 0.56513315 0.27424005 0.81713938 0.8182096\n",
      "  0.51094774 0.43754609 0.24920457 0.399794   0.90277388 0.25562057\n",
      "  0.89646963 0.4205036  0.36665905 0.3731383  0.78676448 0.59550106\n",
      "  0.37237047 0.22086656 0.68913538 0.24498057 0.57691038 0.28989754\n",
      "  0.2884816  0.84547359 0.57608232 0.29370124 0.59151866 0.45812657\n",
      "  0.73836866 0.90696784 0.36364794 0.50462501 0.69735924 0.50183263\n",
      "  0.44043464 0.5274236  0.47050879 0.29986343 0.73088523 0.243401\n",
      "  0.52807042 0.54800015 0.39305097 0.47387784 0.64569192 0.51111479\n",
      "  0.32594948 0.5665225  0.33946462 0.48691932 0.29004087 0.31816095\n",
      "  0.33700826 0.74868769 0.90225082 0.16780308 0.33627056 0.63576177\n",
      "  0.33367695 0.76233207 0.19755786 0.37472116 0.4175051  0.48755478\n",
      "  0.5050212  0.54718073 0.83246642 0.53411957 0.87803264 0.50776546\n",
      "  0.6842366  0.71328772 0.32580936 0.61074725 0.56263812 0.43678004\n",
      "  0.66203484 0.67677985 0.41781867 0.43040694 0.73643772 0.36298781\n",
      "  0.35149665 0.46596728 0.52203142 0.75290371 0.50064935 0.38723181\n",
      "  0.38452126 0.62698683 0.68315737 0.01908863 0.6966154  0.52706407\n",
      "  0.55174324 0.15132433 0.78328999 0.42198839 0.60450929 0.59295192\n",
      "  0.51808493 0.27662205 0.63600901 0.73079654 0.66200352 0.5979365\n",
      "  0.1163431  0.71183384 0.49259229 0.73508911 0.3821604  0.751379\n",
      "  0.67563756 0.13970833 0.51494172 0.66049999 0.68000278 0.54691669\n",
      "  0.72830271 0.40259503 0.4673027  0.44845674 0.69450664 0.65107828]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0.40009171 0.77630008 0.60560108 0.6843421  0.59284755 0.93918652\n",
      "  0.7637324  0.42548886 0.53777818 0.2551237  0.48828518 0.27550091\n",
      "  0.67691203 0.466075   0.19876669 0.76044756 0.50846634 0.27909772\n",
      "  0.91814822 0.28568985 0.71597959 0.78380525 0.6413067  0.44937847\n",
      "  0.87431643 0.71784223 0.75325823 0.52396355 0.14457458 0.14676744\n",
      "  0.50674578 0.67124712 0.94433678 0.75782168 0.16553021 0.29228313\n",
      "  0.38509176 0.42436874 0.90094268 0.82057427 0.60369342 0.7650384\n",
      "  0.70077508 0.3028042  0.61526595 0.49005451 0.28502945 0.90494443\n",
      "  0.92348282 0.44903476 0.42676037 0.33356446 0.83880519 0.2914408\n",
      "  0.77149233 0.56047418 0.79062219 0.31353209 0.20098082 0.70276668\n",
      "  0.75060753 0.50073506 0.18589429 0.40630827 0.93221    0.35397411\n",
      "  0.44993656 0.81527743 0.79510872 0.67962062 0.19976415 0.8540607\n",
      "  0.17340143 0.93779491 0.60751474 0.22563851 0.35857613 0.92878518\n",
      "  0.66161595 0.41826854 0.63597377 0.36892736 0.98371093 0.31394803\n",
      "  0.91333854 0.27394385 0.22721957 0.29778703 0.35012194 0.91958618\n",
      "  0.38377471 0.59436873 0.20146827 0.43694196 0.26764011 0.73781469\n",
      "  0.26457097 0.50465046 0.45594353 0.27191229 0.56415655 0.57546278\n",
      "  0.35931227 0.29417868 0.05043094 0.5965778  0.87334876 0.67202393\n",
      "  0.78534467 0.35944642 0.86560484 0.89352607 0.74436316 0.35655346\n",
      "  0.3009436  0.90554991 0.55478179 0.57145957 0.77549677 0.5481879\n",
      "  0.86866162 0.73848089 0.34833836 0.340563   0.4953217  0.93500318\n",
      "  0.29626933 0.25731895 0.34195891 0.9504662  0.62241021 0.21247837\n",
      "  0.59223894 0.54418818 0.81819705 0.76683195 0.61494286 0.8442543\n",
      "  0.52077296 0.86699752 0.56765482 0.28239918 0.76141363 0.3660929\n",
      "  0.93144821 0.18882016 0.62862591 0.82580261 0.62350968 0.39482381\n",
      "  0.29238715 0.60970686 0.75187886 0.64752922 0.75820901 0.39565164\n",
      "  0.38229509 0.32423292 0.58608559 0.70200358 0.85227853 0.24288594\n",
      "  0.69396232 0.23946792 0.35746319 0.58244226 0.79373552 0.54236266\n",
      "  0.68288863 0.78627355 0.81983171 0.1094666  0.33488477 0.83965475\n",
      "  0.85734653 0.34649572 0.36260091 0.44394961 0.12570123 0.09815054\n",
      "  0.47236354 0.67952262 0.4233077  0.35695303 0.34539545 0.63183866\n",
      "  0.67537633 0.35232582 0.92692553 0.50155947 0.85126464 0.96737429\n",
      "  0.7561096  0.25221205 0.79686992 0.32630256 0.14201808 0.68450806\n",
      "  0.18460112 0.43103416 0.87733329 0.65412607 0.2728891  0.81512701\n",
      "  0.971246   0.52251004 0.32208116 0.70838557 0.5760172  0.58102153\n",
      "  0.79758364 0.44235656 0.43361008 0.1841187  0.1535243  0.23994475\n",
      "  0.65840483 0.87758003 0.88631561 0.79923914 0.7723185  0.46890489\n",
      "  0.79584859 0.41304826 0.65920535 0.87657478 0.28477213 0.72350097\n",
      "  0.87091641 0.66993022 0.52329083 0.63273953 0.66341811 0.58910264\n",
      "  0.40053268 0.31145994 0.90681603 0.2434148  0.44266039 0.83368178\n",
      "  0.49042663 0.72002339 0.66639975 0.78977984 0.54700208 0.98272193\n",
      "  0.4177069  0.79770175 0.3945927  0.83346542 0.15578274 0.20583226\n",
      "  0.39724135 0.67644363 0.73259543 0.55762259 0.84938941 0.64948789\n",
      "  0.75892754 0.86403867 0.11316689 0.40661785 0.62137205 0.79553697\n",
      "  0.92821833 0.65412462 0.58182812 0.40849989 0.90926798 0.53183343\n",
      "  0.37611145 0.74249276 0.64312185 0.32384382 0.22412254 0.51142221\n",
      "  0.4044309  0.26673997 0.48610805 0.44001123 0.74778538 0.85557873\n",
      "  0.57540285 0.61915811 0.50217883 0.25170463 0.26070903 0.41915387\n",
      "  0.36248817 0.37149193 0.84769588 0.4114881  0.81855286 0.39850685\n",
      "  0.29236607 0.5159598  0.70479094 0.2848727  0.3674176  0.75769474\n",
      "  0.32025618 0.62765468 0.21626354 0.67730147 0.46445252 0.39238171\n",
      "  0.89256304 0.37915071 0.71496367 0.40343695 0.76119972 0.32898957\n",
      "  0.64894917 0.71422009 0.43346156 0.64877862 0.31904831 0.47757797\n",
      "  0.71127294 0.40691692 0.09512919 0.27310459 0.38489672 0.95918907\n",
      "  0.82823903 0.60747451 0.728621   0.63844492 0.45437283 0.51068802\n",
      "  0.89064032 0.55628664 0.81117362 0.25164678 0.7577074  0.64833165\n",
      "  0.35858827 0.98208753 0.60465312 0.64348904 0.97373418 0.25448615\n",
      "  0.34216089 0.76415698 0.97615161 0.88533634 0.47612183 0.27507209\n",
      "  0.31225256 0.33829965 0.5390605  0.56630149 0.43522223 0.73154422\n",
      "  0.52177763 0.11223489 0.28795163 0.89150186 0.14721171 0.56868662\n",
      "  0.27280065 0.76486721 0.73381938 0.34665475 0.52371422 0.87064607\n",
      "  0.83684295 0.94423726 0.64314223 0.40945427 0.33909217 0.63123326\n",
      "  0.33882371 0.24030139 0.70068195 0.76763181 0.2712826  0.6281171\n",
      "  0.92421607 0.30249802 0.89101333 0.63097089 0.35108037 0.44808581\n",
      "  0.69915311 0.70202653 0.22697362 0.76271323 0.72597776 0.39228099\n",
      "  0.5781745  0.79196942 0.83880802 0.78413671 0.28517351 0.94173389\n",
      "  0.93603256 0.64313228 0.65926314 0.37906818 0.19176242 0.47957941\n",
      "  0.70493458 0.77303609 0.9658209  0.35675414 0.94916078 0.80982407\n",
      "  0.33199542 0.78299471 0.63584621 0.24672221 0.23145717 0.52085468\n",
      "  0.3501269  0.92186257 0.13895325 0.77936945 0.91832881 0.89078449\n",
      "  0.71156193 0.17864126 0.71097343 0.14096791 0.36685177 0.46288618\n",
      "  0.43895249 0.66902658 0.43388802 0.68720064 0.24116163 0.72587368\n",
      "  0.88357696 0.34232513 0.47440774 0.72619738 0.91267718 0.96830869\n",
      "  0.66093842 0.49522931 0.16828069 0.76736053 0.94822483 0.5815723\n",
      "  0.23399399 0.57005155 0.92928711 0.30131841 0.60239612 0.28963771\n",
      "  0.84283818 0.32116433 0.40039267 0.85162673 0.69960535 0.90575103\n",
      "  0.69128401 0.20775661 0.95140584 0.66961299 0.88181408 0.7491813\n",
      "  0.56146229 0.78171357 0.33631045 0.31746435 0.66277378 0.83814993\n",
      "  0.53528145 0.7880782  0.39569426 0.59255641 0.54943392 0.77412752\n",
      "  0.35209384 0.5918234  0.90866466 0.18234324 0.44105705 0.73338205\n",
      "  0.57264342 0.35925797 0.86588604 0.38523823 0.93179377 0.51014714\n",
      "  0.32183913 0.70856825 0.57488489 0.24988661 0.94610567 0.58391463\n",
      "  0.78595698 0.35041285 0.43269694 0.13878203 0.45071703 0.46186252\n",
      "  0.67786835 0.23169356 0.29238884 0.37230039 0.41748601 0.51101132\n",
      "  0.95678966 0.64131247 0.83907963 0.9749697  0.31709083 0.29025199\n",
      "  0.22800288 0.43326249 0.59536054 0.19297127 0.90247346 0.46167393\n",
      "  0.38648166 0.67857421 0.71451955 0.61161883 0.49637798 0.28975809\n",
      "  0.26183135 0.17653241 0.45124065 0.93746206 0.77469294 0.38967125\n",
      "  0.28506185 0.24752164 0.37427332 0.71412702 0.16804608 0.31542571\n",
      "  0.77026878 0.21149173 0.22174638 0.62116927 0.4933368  0.88543901\n",
      "  0.44521303 0.8787073  0.33409752 0.99346914 0.76210289 0.78632764\n",
      "  0.25501781 0.81935757 0.66562142 0.32204741 0.56147656 0.15553726\n",
      "  0.94243819 0.64569087 0.53873374 0.51504723 0.7295427  0.92539218\n",
      "  0.44075391 0.11770942 0.83351782 0.75976419 0.35935949 0.70750532\n",
      "  0.23623991 0.3676983  0.75641354 0.77801972 0.36685756 0.72791159\n",
      "  0.96699347 0.5475059  0.58116361 0.52534309 0.91087478 0.55808272\n",
      "  0.39196688 0.49650115 0.29523095 0.20216704 0.23714505 0.62838794\n",
      "  0.48642906 0.49485338 0.21126522 0.73327349 0.44223793 0.27893145\n",
      "  0.2787619  0.39255501 0.37119137 0.46989995 0.1324777  0.25535302\n",
      "  0.91992435 0.92456441 0.44486707 0.44575118 0.28443119 0.62910491\n",
      "  0.36690624 0.76468216 0.19563532 0.95031325 0.74466626 0.66153978\n",
      "  0.26334338 0.55257386 0.15884417 0.77482363 0.78726656 0.50893911\n",
      "  0.30206462 0.36231276 0.74531392 0.59208821 0.14966556 0.42436267\n",
      "  0.64684781 0.30018627 0.25478199 0.4595105  0.27024111 0.1245007\n",
      "  0.92260458 0.20258577 0.50449343 0.2096074  0.9273223  0.89942379\n",
      "  0.77360667 0.74372188 0.82200853 0.42625936 0.83770455 0.64573707\n",
      "  0.32923718 0.26994429 0.55146635 0.50795975 0.42332729 0.59275723\n",
      "  0.31362616 0.14893389 0.83430108 0.42006531 0.5324055  0.87611637\n",
      "  0.86944699 0.77955621 0.66959375 0.12965758 0.49004269 0.1113952\n",
      "  0.40908748 0.43960652 0.3947723  0.56357505 0.50447811 0.94650866\n",
      "  0.50399366 0.8176311  0.39460839 0.25804853 0.9541348  0.568457\n",
      "  0.73397034 0.61980233 0.70683085 0.64650666 0.61993214 0.96536014\n",
      "  0.42072261 0.76874203 0.494468   0.6642212  0.74970642 0.39798327\n",
      "  0.73646574 0.1683153  0.67171488 0.20306257 0.31496451 0.72661005\n",
      "  0.89173674 0.78640999 0.36279567 0.71944828 0.4702739  0.94905964\n",
      "  0.28971743 0.90511027 0.34604476 0.76068467 0.94823446 0.72197645\n",
      "  0.34270204 0.29329276 0.53837125 0.77885876 0.35355696 0.63115348\n",
      "  0.50467367 0.8933302  0.59709999 0.39535211 0.57662901 0.23055365\n",
      "  0.70919164 0.29678744 0.75737306 0.36662007 0.3481229  0.5597354\n",
      "  0.68430966 0.32010695 0.91427165 0.17478086 0.57121587 0.80088944\n",
      "  0.61482677 0.65342085 0.24756015 0.8888037  0.57146764 0.33324325\n",
      "  0.71332045 0.75952221 0.57924656 0.51956095 0.76275378 0.32983104\n",
      "  0.30928984 0.72807848 0.31589562 0.68003013 0.7389474  0.82620552\n",
      "  0.72867807 0.38678996 0.79863978 0.53272447 0.28132967 0.40556051\n",
      "  0.31815225 0.91675393 0.40903492 0.88476111 0.81081628 0.67553514\n",
      "  0.37741298 0.97891429 0.30229996 0.2573532  0.72225915 0.59847375\n",
      "  0.82903972 0.50615609 0.75678467 0.52109804 0.66324052 0.61050859\n",
      "  0.25982326 0.67614477 0.42468766 0.54616964 0.30164508 0.33126711\n",
      "  0.67040694 0.34850566 0.33694061 0.2593247  0.62376732 0.74108101\n",
      "  0.24766476 0.33262212 0.55615041 0.49728887 0.43021489 0.32143978\n",
      "  0.2742371  0.72027235 0.63748371 0.35388008 0.25177072 0.69659898\n",
      "  0.86578975 0.79197792 0.3165535  0.68357491]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "train accuracy: 86.20253164556962 %\n",
      "test accuracy: 72.72727272727273 %\n"
     ]
    }
   ],
   "source": [
    "#Run the model!\n",
    "output = model(train_img_unrow, train_labels_final,\n",
    "               test_img_unrow, test_labels_final,\n",
    "               num_iterations = 2000, learning_rate = 0.005,\n",
    "               print_cost = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! In this lab you implemented your first neural network in order to identify images of Santa! In upcoming labs you'll see how to extend your neural networks to include a larger number of layers and how to then successively prune these complex schemas to improve test and train accuracies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
